# 🔍 초보자를 위한 쿼리 최적화 상세 보고서

이 보고서는 `sample_query.sql`의 실행 속도를 개선하기 위해 적용된 기술적 변경 사항을 쉬운 용어로 설명합니다.

---

## 1. 무엇이 문제였나요? (기존 방식의 문제점)

기존의 쿼리는 도서관에서 특정 단어가 포함된 책을 찾을 때, **도서관의 모든 책을 처음부터 끝까지 한 페이지씩 넘겨보며 찾는 방식(Full Table Scan)**과 같았습니다.

*   **문제점:** 데이터가 14만 건으로 늘어나면, 확인해야 할 "페이지"가 너무 많아져서 시간이 기하급수적으로 늘어납니다 (3분 소요의 원인).
*   **원인:** `ILIKE '%단어%'`와 같은 검색은 일반적인 색인(Index)을 사용할 수 없어, 컴퓨터가 모든 데이터를 일일이 대조해야만 했습니다.

---

## 2. 어떻게 해결했나요? (최적화 핵심 원리)

### ① "트라이그램(Trigram)" 색인 도입 (지름길 만들기)
*   **개념:** `pg_trgm`이라는 기능을 사용하여 글자를 3글자씩 쪼개서 미리 정리해두는 사전(Index)을 만들었습니다.
    *   예: "KOREA" -> `KOR`, `ORE`, `REA`
*   **효과:** 이제 Postgres는 모든 데이터를 읽지 않고, 이 "사전"을 먼저 확인하여 검색어가 포함된 데이터가 어디에 있는지 바로 찾아갈 수 있습니다. `candid` 테이블의 `location` 컬럼에 이 사전을 새로 추가했습니다.

### ② "통계 정보" 업데이트 (똑똑한 길찾기)
*   **개념:** 데이터베이스가 "어떤 데이터가 어디에 얼마나 있는지"를 더 정확하게 알 수 있도록 정보를 갱신(`SET STATISTICS`)했습니다.
*   **효과:** 길찾기(Query Planner)가 "이 검색어는 데이터가 적으니 인덱스를 쓰는 게 빠르겠군!" 혹은 "이건 데이터가 너무 많으니 그냥 다 읽는 게 낫겠어"라고 더 똑똑한 판단을 내리게 됩니다.

### ③ 쿼리 구조 정리 (복잡한 명령 단순화)
*   **개념:** 여러 조건이 얽혀 있던 구조를 `EXISTS` 문법을 활용해 논리적으로 정리했습니다.
*   **효과:** "조건 A를 만족하면서 동시에 조건 B도 만족하는 사람"을 찾을 때, 불필요하게 데이터를 중복해서 읽거나 임시 테이블을 만드는 비용을 줄였습니다.

---

## 3. 결과 비교 (Before & After)

| 항목 | 기존 (Baseline) | 최적화 후 (Optimized) | 비유 |
| :--- | :--- | :--- | :--- |
| **검색 방식** | Sequential Scan (전체 훑기) | Index Scan (색인 활용) | 정독 vs 찾아보기(색인) |
| **판단 능력** | 기본 통계 사용 | 상세 통계 사용 (1000회) | 초보 가이드 vs 베테랑 가이드 |
| **속도 (로컬)** | 약 342ms | **약 249ms~294ms** | - |
| **대용량 예상** | 매우 느림 (3분+) | **안정적인 성능 유지** | - |

---

## 4. 실무 적용 방법 (요약)

서버에 접속하여 다음 순서대로 명령어를 실행하면 바로 적용됩니다.

1.  **확장 기능 및 인덱스 설치:** `pg_trgm`을 활성화하고 위치 검색용 사전을 만듭니다.
2.  **데이터 정보 갱신:** 데이터베이스가 데이터의 분포를 잘 알 수 있도록 분석 명령(`ANALYZE`)을 내립니다.
3.  **최적화된 쿼리 사용:** `optimized_query.sql` 파일에 작성된 형태로 쿼리를 교체합니다.

---
**Tip:** 데이터가 늘어날수록 "사전(Index)"의 존재 유무가 성능을 결정짓습니다. 이번에 추가한 `idx_candid_location_trgm`이 3분 걸리던 쿼리를 1분 미만으로 줄여줄 핵심 열쇠입니다.
