{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80dd8e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting supabase\n",
      "  Downloading supabase-2.27.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting psycopg\n",
      "  Downloading psycopg-3.3.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting realtime==2.27.3 (from supabase)\n",
      "  Downloading realtime-2.27.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting supabase-functions==2.27.3 (from supabase)\n",
      "  Downloading supabase_functions-2.27.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting storage3==2.27.3 (from supabase)\n",
      "  Downloading storage3-2.27.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting supabase-auth==2.27.3 (from supabase)\n",
      "  Downloading supabase_auth-2.27.3-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting postgrest==2.27.3 (from supabase)\n",
      "  Downloading postgrest-2.27.3-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx<0.29,>=0.26 (from supabase)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting yarl>=1.22.0 (from supabase)\n",
      "  Downloading yarl-1.22.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (75 kB)\n",
      "Collecting deprecation>=2.1.0 (from postgrest==2.27.3->supabase)\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pydantic<3.0,>=1.9 (from postgrest==2.27.3->supabase)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting typing-extensions>=4.14.0 (from realtime==2.27.3->supabase)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting websockets<16,>=11 (from realtime==2.27.3->supabase)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting pyiceberg>=0.10.0 (from storage3==2.27.3->supabase)\n",
      "  Downloading pyiceberg-0.11.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Collecting pyjwt>=2.10.1 (from pyjwt[crypto]>=2.10.1->supabase-auth==2.27.3->supabase)\n",
      "  Downloading pyjwt-2.11.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting strenum>=0.4.15 (from supabase-functions==2.27.3->supabase)\n",
      "  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting anyio (from httpx<0.29,>=0.26->supabase)\n",
      "  Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting certifi (from httpx<0.29,>=0.26->supabase)\n",
      "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<0.29,>=0.26->supabase)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<0.29,>=0.26->supabase)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<0.29,>=0.26->supabase)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting h2<5,>=3 (from httpx[http2]<0.29,>=0.26->postgrest==2.27.3->supabase)\n",
      "  Downloading h2-4.3.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[http2]<0.29,>=0.26->postgrest==2.27.3->supabase)\n",
      "  Downloading hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[http2]<0.29,>=0.26->postgrest==2.27.3->supabase)\n",
      "  Downloading hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0,>=1.9->postgrest==2.27.3->supabase)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3.0,>=1.9->postgrest==2.27.3->supabase)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0,>=1.9->postgrest==2.27.3->supabase)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: packaging in /Users/kimdain/Workspace/Harper/.venv/lib/python3.12/site-packages (from deprecation>=2.1.0->postgrest==2.27.3->supabase) (26.0)\n",
      "Collecting mmh3<6.0.0,>=4.0.0 (from pyiceberg>=0.10.0->storage3==2.27.3->supabase)\n",
      "  Downloading mmh3-5.2.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (14 kB)\n",
      "Collecting requests<3.0.0,>=2.20.0 (from pyiceberg>=0.10.0->storage3==2.27.3->supabase)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting click<9.0.0,>=7.1.1 (from pyiceberg>=0.10.0->storage3==2.27.3->supabase)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting rich<15.0.0,>=10.11.0 (from pyiceberg>=0.10.0->storage3==2.27.3->supabase)\n",
      "  Downloading rich-14.3.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting strictyaml<2.0.0,>=1.7.0 (from pyiceberg>=0.10.0->storage3==2.27.3->supabase)\n",
      "  Downloading strictyaml-1.7.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fsspec>=2023.1.0 (from pyiceberg>=0.10.0->storage3==2.27.3->supabase)\n",
      "  Downloading fsspec-2026.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pyparsing<4.0.0,>=3.1.0 (from pyiceberg>=0.10.0->storage3==2.27.3->supabase)\n",
      "  Downloading pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tenacity<10.0.0,>=8.2.3 (from pyiceberg>=0.10.0->storage3==2.27.3->supabase)\n",
      "  Downloading tenacity-9.1.4-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting pyroaring<2.0.0,>=1.0.0 (from pyiceberg>=0.10.0->storage3==2.27.3->supabase)\n",
      "  Downloading pyroaring-1.0.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting cachetools<7.0,>=5.5 (from pyiceberg>=0.10.0->storage3==2.27.3->supabase)\n",
      "  Downloading cachetools-6.2.6-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting zstandard<1.0.0,>=0.13.0 (from pyiceberg>=0.10.0->storage3==2.27.3->supabase)\n",
      "  Downloading zstandard-0.25.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3.0.0,>=2.20.0->pyiceberg>=0.10.0->storage3==2.27.3->supabase)\n",
      "  Downloading charset_normalizer-3.4.4-cp312-cp312-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.20.0->pyiceberg>=0.10.0->storage3==2.27.3->supabase)\n",
      "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<15.0.0,>=10.11.0->pyiceberg>=0.10.0->storage3==2.27.3->supabase)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/kimdain/Workspace/Harper/.venv/lib/python3.12/site-packages (from rich<15.0.0,>=10.11.0->pyiceberg>=0.10.0->storage3==2.27.3->supabase) (2.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.0 in /Users/kimdain/Workspace/Harper/.venv/lib/python3.12/site-packages (from strictyaml<2.0.0,>=1.7.0->pyiceberg>=0.10.0->storage3==2.27.3->supabase) (2.9.0.post0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<15.0.0,>=10.11.0->pyiceberg>=0.10.0->storage3==2.27.3->supabase)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cryptography>=3.4.0 (from pyjwt[crypto]>=2.10.1->supabase-auth==2.27.3->supabase)\n",
      "  Downloading cryptography-46.0.4-cp311-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
      "Collecting cffi>=2.0.0 (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->supabase-auth==2.27.3->supabase)\n",
      "  Downloading cffi-2.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.6 kB)\n",
      "Collecting pycparser (from cffi>=2.0.0->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->supabase-auth==2.27.3->supabase)\n",
      "  Downloading pycparser-3.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kimdain/Workspace/Harper/.venv/lib/python3.12/site-packages (from python-dateutil>=2.6.0->strictyaml<2.0.0,>=1.7.0->pyiceberg>=0.10.0->storage3==2.27.3->supabase) (1.17.0)\n",
      "Collecting multidict>=4.0 (from yarl>=1.22.0->supabase)\n",
      "  Downloading multidict-6.7.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.1 (from yarl>=1.22.0->supabase)\n",
      "  Downloading propcache-0.4.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Downloading supabase-2.27.3-py3-none-any.whl (16 kB)\n",
      "Downloading postgrest-2.27.3-py3-none-any.whl (22 kB)\n",
      "Downloading realtime-2.27.3-py3-none-any.whl (22 kB)\n",
      "Downloading storage3-2.27.3-py3-none-any.whl (27 kB)\n",
      "Downloading supabase_auth-2.27.3-py3-none-any.whl (48 kB)\n",
      "Downloading supabase_functions-2.27.3-py3-none-any.whl (8.8 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading h2-4.3.0-py3-none-any.whl (61 kB)\n",
      "Downloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Downloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-15.0.1-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading psycopg-3.3.2-py3-none-any.whl (212 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading pyiceberg-0.11.0-cp312-cp312-macosx_11_0_arm64.whl (532 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.9/532.9 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-6.2.6-py3-none-any.whl (11 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading mmh3-5.2.0-cp312-cp312-macosx_11_0_arm64.whl (40 kB)\n",
      "Downloading pyparsing-3.3.2-py3-none-any.whl (122 kB)\n",
      "Downloading pyroaring-1.0.3-cp312-cp312-macosx_11_0_arm64.whl (314 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp312-cp312-macosx_10_13_universal2.whl (208 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading rich-14.3.2-py3-none-any.whl (309 kB)\n",
      "Downloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
      "Downloading tenacity-9.1.4-py3-none-any.whl (28 kB)\n",
      "Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Downloading zstandard-0.25.0-cp312-cp312-macosx_11_0_arm64.whl (640 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m640.4/640.4 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Downloading fsspec-2026.2.0-py3-none-any.whl (202 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading pyjwt-2.11.0-py3-none-any.whl (28 kB)\n",
      "Downloading cryptography-46.0.4-cp311-abi3-macosx_10_9_universal2.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cffi-2.0.0-cp312-cp312-macosx_11_0_arm64.whl (181 kB)\n",
      "Downloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading yarl-1.22.0-cp312-cp312-macosx_11_0_arm64.whl (94 kB)\n",
      "Downloading multidict-6.7.1-cp312-cp312-macosx_11_0_arm64.whl (43 kB)\n",
      "Downloading propcache-0.4.1-cp312-cp312-macosx_11_0_arm64.whl (47 kB)\n",
      "Downloading anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Downloading pycparser-3.0-py3-none-any.whl (48 kB)\n",
      "Installing collected packages: strenum, pyroaring, zstandard, websockets, urllib3, typing-extensions, tenacity, pyparsing, pyjwt, pycparser, propcache, multidict, mmh3, mdurl, idna, hyperframe, hpack, h11, fsspec, deprecation, click, charset_normalizer, certifi, cachetools, annotated-types, yarl, typing-inspection, strictyaml, requests, pydantic-core, psycopg, markdown-it-py, httpcore, h2, cffi, anyio, rich, pydantic, httpx, cryptography, realtime, pyiceberg, supabase-functions, supabase-auth, storage3, postgrest, supabase\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47/47\u001b[0m [supabase]supabase]pyiceberg]hy]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 anyio-4.12.1 cachetools-6.2.6 certifi-2026.1.4 cffi-2.0.0 charset_normalizer-3.4.4 click-8.3.1 cryptography-46.0.4 deprecation-2.1.0 fsspec-2026.2.0 h11-0.16.0 h2-4.3.0 hpack-4.1.0 httpcore-1.0.9 httpx-0.28.1 hyperframe-6.1.0 idna-3.11 markdown-it-py-4.0.0 mdurl-0.1.2 mmh3-5.2.0 multidict-6.7.1 postgrest-2.27.3 propcache-0.4.1 psycopg-3.3.2 pycparser-3.0 pydantic-2.12.5 pydantic-core-2.41.5 pyiceberg-0.11.0 pyjwt-2.11.0 pyparsing-3.3.2 pyroaring-1.0.3 realtime-2.27.3 requests-2.32.5 rich-14.3.2 storage3-2.27.3 strenum-0.4.15 strictyaml-1.7.3 supabase-2.27.3 supabase-auth-2.27.3 supabase-functions-2.27.3 tenacity-9.1.4 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.6.3 websockets-15.0.1 yarl-1.22.0 zstandard-0.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install supabase psycopg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a21bf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supabase import create_client\n",
    "\n",
    "import os\n",
    "\n",
    "SUPABASE_URL = \"https://zzojrniuppueizhnmqfd.supabase.co\"\n",
    "SUPABASE_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Inp6b2pybml1cHB1ZWl6aG5tcWZkIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjU1MTg3NDYsImV4cCI6MjA4MTA5NDc0Nn0.ctuOSKEpdyPF9OaTsU4OC49VjYRxG22mC7A03LcH6h0\"\n",
    "\n",
    "supabase = create_client(SUPABASE_URL, SUPABASE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33205f38",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIError",
     "evalue": "{'message': 'syntax error at or near \"LIMIT\"', 'code': '42601', 'hint': None, 'details': None}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):\n\u001b[32m      7\u001b[39m     st = time.time()\n\u001b[32m      8\u001b[39m     result = \u001b[43msupabase\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mset_timeout_and_execute_raw_sql\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msql_query\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpage_idx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlimit_num\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moffset_num\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(time.time() - st, \u001b[33m\"\u001b[39m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Harper/.venv/lib/python3.12/site-packages/postgrest/_sync/request_builder.py:82\u001b[39m, in \u001b[36mSyncSingleRequestBuilder.execute\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     81\u001b[39m         json_obj = model_validate_json(APIErrorFromJSON, r.content)\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m APIError(\u001b[38;5;28mdict\u001b[39m(json_obj))\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m APIError(generate_default_error_message(r))\n",
      "\u001b[31mAPIError\u001b[39m: {'message': 'syntax error at or near \"LIMIT\"', 'code': '42601', 'hint': None, 'details': None}"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "sql = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "for _ in range(5):\n",
    "    st = time.time()\n",
    "    result = supabase.rpc(\n",
    "        \"set_timeout_and_execute_raw_sql\",\n",
    "        {\n",
    "            \"sql_query\": sql,\n",
    "            \"page_idx\": 0,\n",
    "            \"limit_num\": 50,\n",
    "            \"offset_num\": 0,\n",
    "        },\n",
    "    ).execute()\n",
    "    print(time.time() - st, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4333bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "import statistics\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "\n",
    "import psycopg\n",
    "\n",
    "# Adjust these for your workload\n",
    "DATABASE_URL = \"postgresql://postgres:harperdataset!@db.zzojrniuppueizhnmqfd.supabase.co:5432/postgres\"\n",
    "TSQUERY = \"engineer | researcher | developder | software | scientist | system <-> engineer | computer\"\n",
    "LANG = os.environ.get(\"TSLANG\", \"english\")\n",
    "\n",
    "LIMIT = int(os.environ.get(\"LIMIT\", \"100\"))\n",
    "WARMUP = int(os.environ.get(\"WARMUP\", \"3\"))\n",
    "RUNS = int(os.environ.get(\"RUNS\", \"20\"))\n",
    "\n",
    "# Optional: make sure no disk spill during sort affects results unpredictably\n",
    "WORK_MEM_MB = int(os.environ.get(\"WORK_MEM_MB\", \"128\"))\n",
    "\n",
    "# Optional: avoid long hangs\n",
    "STATEMENT_TIMEOUT_MS = int(os.environ.get(\"STATEMENT_TIMEOUT_MS\", \"180000\"))  # 3 min\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Queries (same WHERE)\n",
    "# -----------------------------\n",
    "# Using a CTE to ensure the tsquery is built once per query execution.\n",
    "Q_ORDER_BY_ID = f\"\"\"\n",
    "WITH q AS (\n",
    "  SELECT to_tsquery(%s, %s) AS tsq\n",
    ")\n",
    "SELECT c.id\n",
    "FROM candid c\n",
    "CROSS JOIN q\n",
    "WHERE c.fts @@ q.tsq\n",
    "ORDER BY c.id\n",
    "LIMIT {LIMIT};\n",
    "\"\"\"\n",
    "\n",
    "Q_ORDER_BY_RANK = f\"\"\"\n",
    "WITH q AS (\n",
    "  SELECT to_tsquery(%s, %s) AS tsq\n",
    ")\n",
    "SELECT c.id\n",
    "FROM candid c\n",
    "CROSS JOIN q\n",
    "WHERE c.fts @@ q.tsq\n",
    "ORDER BY ts_rank(c.fts, q.tsq) DESC\n",
    "LIMIT {LIMIT};\n",
    "\"\"\"\n",
    "\n",
    "# EXPLAIN versions (FORMAT JSON is easiest to parse)\n",
    "EXPLAIN_PREFIX = \"EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) \"\n",
    "X_ORDER_BY_ID = EXPLAIN_PREFIX + Q_ORDER_BY_ID\n",
    "X_ORDER_BY_RANK = EXPLAIN_PREFIX + Q_ORDER_BY_RANK\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class RunResult:\n",
    "    client_ms: float\n",
    "    server_exec_ms: Optional[float]\n",
    "    planning_ms: Optional[float]\n",
    "    execution_ms: Optional[float]\n",
    "    rows: Optional[int]\n",
    "    sort_method: Optional[str]\n",
    "    sort_space_kb: Optional[int]\n",
    "    buffers_shared_hit: Optional[int]\n",
    "    buffers_shared_read: Optional[int]\n",
    "\n",
    "\n",
    "def pct(values: List[float], p: float) -> float:\n",
    "    \"\"\"Percentile with linear interpolation.\"\"\"\n",
    "    if not values:\n",
    "        return float(\"nan\")\n",
    "    xs = sorted(values)\n",
    "    if len(xs) == 1:\n",
    "        return xs[0]\n",
    "    k = (len(xs) - 1) * (p / 100.0)\n",
    "    f = int(k)\n",
    "    c = min(f + 1, len(xs) - 1)\n",
    "    if f == c:\n",
    "        return xs[f]\n",
    "    return xs[f] + (xs[c] - xs[f]) * (k - f)\n",
    "\n",
    "\n",
    "def safe_get(d: Dict[str, Any], path: List[str]) -> Optional[Any]:\n",
    "    cur: Any = d\n",
    "    for key in path:\n",
    "        if not isinstance(cur, dict) or key not in cur:\n",
    "            return None\n",
    "        cur = cur[key]\n",
    "    return cur\n",
    "\n",
    "\n",
    "def find_first_plan_node(plan: Dict[str, Any], node_type: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"DFS to find first node whose 'Node Type' matches.\"\"\"\n",
    "    stack = [plan]\n",
    "    while stack:\n",
    "        n = stack.pop()\n",
    "        if isinstance(n, dict) and n.get(\"Node Type\") == node_type:\n",
    "            return n\n",
    "        if isinstance(n, dict) and \"Plans\" in n and isinstance(n[\"Plans\"], list):\n",
    "            stack.extend(n[\"Plans\"])\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_explain_metrics(explain_json: Any) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    explain_json comes as:\n",
    "      [ { \"Plan\": {...}, \"Planning Time\": x, \"Execution Time\": y, ... } ]\n",
    "    \"\"\"\n",
    "    top = explain_json[0] if isinstance(explain_json, list) and explain_json else {}\n",
    "    plan = top.get(\"Plan\", {}) if isinstance(top, dict) else {}\n",
    "\n",
    "    planning_ms = top.get(\"Planning Time\")\n",
    "    execution_ms = top.get(\"Execution Time\")\n",
    "    server_exec_ms = (planning_ms + execution_ms) if (planning_ms is not None and execution_ms is not None) else None\n",
    "\n",
    "    # Rows actually returned by the top plan node\n",
    "    rows = plan.get(\"Actual Rows\")\n",
    "\n",
    "    # Sort info (if Sort node exists)\n",
    "    sort_node = find_first_plan_node(plan, \"Sort\")\n",
    "    sort_method = sort_node.get(\"Sort Method\") if sort_node else None\n",
    "    sort_space_kb = sort_node.get(\"Sort Space Used\") if sort_node else None  # often in kB\n",
    "\n",
    "    # Buffers: summarize shared hit/read at the top plan node (good enough for comparison)\n",
    "    buf_hit = safe_get(plan, [\"Shared Hit Blocks\"])\n",
    "    buf_read = safe_get(plan, [\"Shared Read Blocks\"])\n",
    "\n",
    "    return {\n",
    "        \"planning_ms\": planning_ms,\n",
    "        \"execution_ms\": execution_ms,\n",
    "        \"server_exec_ms\": server_exec_ms,\n",
    "        \"rows\": rows,\n",
    "        \"sort_method\": sort_method,\n",
    "        \"sort_space_kb\": sort_space_kb,\n",
    "        \"buffers_shared_hit\": buf_hit,\n",
    "        \"buffers_shared_read\": buf_read,\n",
    "        \"plan_root\": plan,\n",
    "    }\n",
    "\n",
    "\n",
    "def run_explain(conn: psycopg.Connection, sql: str, params: Tuple[Any, ...]) -> Tuple[RunResult, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Executes EXPLAIN (ANALYZE...) and returns:\n",
    "      - measured client latency\n",
    "      - parsed EXPLAIN metrics\n",
    "    \"\"\"\n",
    "    t0 = time.perf_counter()\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(sql, params)\n",
    "        row = cur.fetchone()\n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "    # EXPLAIN FORMAT JSON returns one column containing JSON.\n",
    "    explain_json = row[0]\n",
    "    metrics = extract_explain_metrics(explain_json)\n",
    "\n",
    "    rr = RunResult(\n",
    "        client_ms=(t1 - t0) * 1000.0,\n",
    "        server_exec_ms=metrics[\"server_exec_ms\"],\n",
    "        planning_ms=metrics[\"planning_ms\"],\n",
    "        execution_ms=metrics[\"execution_ms\"],\n",
    "        rows=metrics[\"rows\"],\n",
    "        sort_method=metrics[\"sort_method\"],\n",
    "        sort_space_kb=metrics[\"sort_space_kb\"],\n",
    "        buffers_shared_hit=metrics[\"buffers_shared_hit\"],\n",
    "        buffers_shared_read=metrics[\"buffers_shared_read\"],\n",
    "    )\n",
    "    return rr, metrics\n",
    "\n",
    "\n",
    "def summarize(name: str, results: List[RunResult]) -> None:\n",
    "    client = [r.client_ms for r in results]\n",
    "    server = [r.server_exec_ms for r in results if r.server_exec_ms is not None]\n",
    "\n",
    "    def line(label: str, xs: List[float]) -> str:\n",
    "        return (\n",
    "            f\"{label:>10}  \"\n",
    "            f\"median={statistics.median(xs):8.2f} ms  \"\n",
    "            f\"p95={pct(xs, 95):8.2f} ms  \"\n",
    "            f\"mean={statistics.mean(xs):8.2f} ms  \"\n",
    "            f\"min={min(xs):8.2f} ms  \"\n",
    "            f\"max={max(xs):8.2f} ms\"\n",
    "        )\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(line(\"client\", client))\n",
    "    if server:\n",
    "        print(line(\"server\", server))\n",
    "\n",
    "    # Some helpful “what happened” signals\n",
    "    rows = [r.rows for r in results if r.rows is not None]\n",
    "    if rows:\n",
    "        print(f\"{'rows':>10}  median={statistics.median(rows)}  min={min(rows)}  max={max(rows)}\")\n",
    "\n",
    "    sorts = [r.sort_method for r in results if r.sort_method]\n",
    "    if sorts:\n",
    "        # show most common sort method\n",
    "        common = max(set(sorts), key=sorts.count)\n",
    "        print(f\"{'sort':>10}  most_common={common}  samples={len(sorts)}/{len(results)}\")\n",
    "\n",
    "    reads = [r.buffers_shared_read for r in results if r.buffers_shared_read is not None]\n",
    "    hits = [r.buffers_shared_hit for r in results if r.buffers_shared_hit is not None]\n",
    "    if reads and hits:\n",
    "        print(f\"{'buffers':>10}  shared_read(median)={int(statistics.median(reads))}  shared_hit(median)={int(statistics.median(hits))}\")\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    params = (LANG, TSQUERY)\n",
    "\n",
    "    # Note: autocommit helps keep timings cleaner (no implicit transaction overhead)\n",
    "    with psycopg.connect(DATABASE_URL, autocommit=True) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            # Make the runs more comparable\n",
    "            cur.execute(f\"SET statement_timeout = {STATEMENT_TIMEOUT_MS};\")\n",
    "            cur.execute(f\"SET work_mem = '{WORK_MEM_MB}MB';\")\n",
    "            # Keep these stable; you can comment them out if you prefer defaults\n",
    "            cur.execute(\"SET jit = off;\")  # jit can add variance for small queries\n",
    "            cur.execute(\"SET enable_partitionwise_aggregate = on;\")\n",
    "\n",
    "        print(\"Connected.\")\n",
    "        print(f\"TSLANG={LANG}\")\n",
    "        print(f\"TSQUERY={TSQUERY}\")\n",
    "        print(f\"LIMIT={LIMIT}  WARMUP={WARMUP}  RUNS={RUNS}\")\n",
    "        print(f\"work_mem={WORK_MEM_MB}MB  statement_timeout={STATEMENT_TIMEOUT_MS}ms\")\n",
    "\n",
    "        # Warmup both variants (caches + plan)\n",
    "        print(\"\\nWarming up...\")\n",
    "        for _ in range(WARMUP):\n",
    "            run_explain(conn, X_ORDER_BY_ID, params)\n",
    "            run_explain(conn, X_ORDER_BY_RANK, params)\n",
    "\n",
    "        # Actual benchmark (interleave to reduce drift effects)\n",
    "        id_results: List[RunResult] = []\n",
    "        rank_results: List[RunResult] = []\n",
    "        last_id_plan: Optional[Dict[str, Any]] = None\n",
    "        last_rank_plan: Optional[Dict[str, Any]] = None\n",
    "\n",
    "        print(\"\\nRunning benchmark...\")\n",
    "        for i in range(RUNS):\n",
    "            r1, m1 = run_explain(conn, X_ORDER_BY_ID, params)\n",
    "            id_results.append(r1)\n",
    "            last_id_plan = m1\n",
    "\n",
    "            r2, m2 = run_explain(conn, X_ORDER_BY_RANK, params)\n",
    "            rank_results.append(r2)\n",
    "            last_rank_plan = m2\n",
    "\n",
    "            print(\n",
    "                f\"Run {i+1:02d}/{RUNS}: \"\n",
    "                f\"id client={r1.client_ms:7.2f}ms, rank client={r2.client_ms:7.2f}ms\"\n",
    "            )\n",
    "\n",
    "        summarize(\"ORDER BY id\", id_results)\n",
    "        summarize(\"ORDER BY ts_rank DESC\", rank_results)\n",
    "\n",
    "        # Ratio (median client latency)\n",
    "        id_med = statistics.median([r.client_ms for r in id_results])\n",
    "        rank_med = statistics.median([r.client_ms for r in rank_results])\n",
    "        ratio = (rank_med / id_med) if id_med > 0 else float(\"inf\")\n",
    "        print(f\"\\nMedian latency ratio (rank/id): {ratio:.2f}x\")\n",
    "\n",
    "        # Print a compact plan hint (root node + whether Sort appears)\n",
    "        def plan_hint(metrics: Dict[str, Any]) -> str:\n",
    "            plan = metrics.get(\"plan_root\", {})\n",
    "            node = plan.get(\"Node Type\")\n",
    "            rows = plan.get(\"Actual Rows\")\n",
    "            # Find first Sort node (if any)\n",
    "            sort_node = find_first_plan_node(plan, \"Sort\")\n",
    "            sort_method = sort_node.get(\"Sort Method\") if sort_node else None\n",
    "            return f\"root={node}, rows={rows}, sort={sort_method}\"\n",
    "\n",
    "        if last_id_plan and last_rank_plan:\n",
    "            print(\"\\nPlan hints (last run):\")\n",
    "            print(f\"  id   : {plan_hint(last_id_plan)}\")\n",
    "            print(f\"  rank : {plan_hint(last_rank_plan)}\")\n",
    "\n",
    "        print(\"\\nDone.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
